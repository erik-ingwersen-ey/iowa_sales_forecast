"""
BigQuery Model Training and Execution Module.

This module provides functionality for creating, executing, and managing
'ARIMA_PLUS_XREG' models using Google BigQuery. The module includes
functions to generate SQL queries for creating models, executing these
queries with retries, and evaluating model performance.

Functions
---------
* `create_model_query`: Generate an SQL query to create an ARIMA_PLUS_XREG model
  for a specified item and its associated data.

* `execute_query_with_retries`: Execute a given SQL query with retry logic in case of failure.

* `create_models_for_items`: Create 'ARIMA_PLUS_XREG' models for a list of items
  by executing generated SQL queries.

* `train_arima_models`: Train ARIMA models for specified columns,
  executes the corresponding SQL queries, and stores the model metrics in BigQuery tables.

Notes
-----
This module is designed to work with Google BigQuery and requires a valid
BigQuery client instance. The models generated by this module are intended
for forecasting time series data, with options to handle holiday effects,
step changes, and data cleaning.

See Also
--------
Google BigQuery: https://cloud.google.com/bigquery
BigQuery ML: https://cloud.google.com/bigquery-ml
"""
from __future__ import annotations

import time
from typing import List

from google.cloud import bigquery  # pylint: disable=no-name-in-module
from rich.progress import track

from iowa_forecast.utils import normalize_item_name


def create_model_query(  # pylint: disable=too-many-arguments
    item_name: str,
    timestamp_col: str = "date",
    time_series_data_col: str = "total_amount_sold",
    model_name: str = "bqmlforecast.arima_plus_xreg_model",
    train_table_name: str = "bqmlforecast.training_data",
    test_table_name: str = "bqmlforecast.test_data",
    holiday_region: str = "US",
    auto_arima: bool = True,
    adjust_step_changes: bool = True,
    clean_spikes_and_dips: bool = True,
) -> str:
    """
    Generate a BigQuery 'CREATE MODEL' query for a specified item.

    This function constructs an SQL query to create an ARIMA_PLUS_XREG
    model in BigQuery, tailored for the provided item and its associated
    data.

    Parameters
    ----------
    item_name : str
        Name of the item for which the model is to be created.
    timestamp_col : str, default="date"
        The column name representing the timestamp in the dataset.
    time_series_data_col : str, default="total_amount_sold"
        The column name representing the time series data.
    model_name : str, default="bqmlforecast.arima_plus_xreg_model"
        The base name for the model.
    train_table_name : str, default="bqmlforecast.training_data"
        The name of the table containing training data.
    test_table_name : str, default="bqmlforecast.test_data"
        The name of the table containing test data.
    holiday_region : str, default="US"
        The holiday region to be used by the model.
    auto_arima : bool, default=True
        Whether to enable AUTO_ARIMA.
    adjust_step_changes : bool, default=True
        Whether to adjust for step changes in the data.
    clean_spikes_and_dips : bool, default=True
        Whether to clean spikes and dips in the data.

    Returns
    -------
    str
        A SQL query string for creating the specified model.
    """
    item_name_norm = normalize_item_name(item_name)
    return f"""
    CREATE OR REPLACE MODEL `{model_name}_{item_name_norm}`
    OPTIONS(
      MODEL_TYPE='ARIMA_PLUS_XREG',
      TIME_SERIES_TIMESTAMP_COL='{timestamp_col}',
      TIME_SERIES_DATA_COL='{time_series_data_col}',
      HOLIDAY_REGION='{holiday_region}',
      AUTO_ARIMA={auto_arima},
      ADJUST_STEP_CHANGES={adjust_step_changes},
      CLEAN_SPIKES_AND_DIPS={clean_spikes_and_dips}
    ) AS
    SELECT
        *
    FROM
        `{train_table_name}`
    WHERE
        item_name = "{item_name}"
    UNION ALL
        (
            SELECT
                *
            FROM (
                SELECT
                    t2.*
                FROM
                    `{test_table_name}` AS  t2
                JOIN
                    (
                        SELECT
                            item_name,
                            MAX({timestamp_col}) AS max_date
                        FROM
                            `{train_table_name}`
                        GROUP BY
                            item_name
                    ) AS md
                ON
                    t2.item_name = md.item_name
                WHERE
                    t2.{timestamp_col} > md.max_date
                    AND t2.item_name = "{item_name}"
            )
        )
    ORDER BY
        date
    """


def execute_query_with_retries(
    client: bigquery.Client,
    query: str,
    max_retries: int = 3,
) -> None:
    """
    Execute a BigQuery SQL query with retries on failure.

    This function executes a given SQL query using a BigQuery client.
    If the query fails, it will automatically retry up to `max_retries`
    times, with an increasing delay between each attempt.

    Parameters
    ----------
    client : bigquery.Client
        Instance of the BigQuery client used to execute the query.
    query : str
        The SQL query to be executed.
    max_retries : int, default=3
        Maximum number of retry attempts in case of query failure.

    Raises
    ------
    Exception
        Raises an exception if all retry attempts fail.

    Notes
    -----
    The delay between retries increases linearly by 120 seconds
    multiplied by the current attempt number.

    Examples
    --------
    Execute a query with the default number of retries:

    >>> client = bigquery.Client()
    >>> query = "SELECT * FROM `my_dataset.my_table`"
    >>> execute_query_with_retries(client, query)
    """
    tries = 0
    success = False
    while not success and tries < max_retries:
        try:
            query_job = client.query(query)
            query_job.result()
            success = True
        except Exception as exc:  # pylint: disable=broad-except
            tries += 1
            sleep_time = 120 * tries
            print(exc)
            print(f"Attempt {tries} failed. Sleeping for {sleep_time} seconds...")
            time.sleep(sleep_time)


def create_models_for_items(  # pylint: disable=too-many-arguments
    client: bigquery.Client,
    items_list: List[str],
    max_items: int | None = None,
    timestamp_col: str = "date",
    time_series_data_col: str = "total_amount_sold",
    model_name: str = "bqmlforecast.arima_plus_xreg_model",
    train_table_name: str = "bqmlforecast.training_data",
    test_table_name: str = "bqmlforecast.test_data",
    holiday_region: str = "US",
    auto_arima: bool = True,
    adjust_step_changes: bool = True,
    clean_spikes_and_dips: bool = True,
) -> None:
    """
    Create ARIMA_PLUS_XREG models for a list of items.

    This function generates and executes a CREATE MODEL query
    for each item in the provided list. The models are created
    using the specified training and test tables in BigQuery.

    Parameters
    ----------
    client : bigquery.Client
        Instance of the BigQuery client used to execute queries.
    items_list : List[str]
        List of item names for which models are to be created.
    max_items : int or None, default=None
        Maximum number of items to process. If None, all items are processed.
        See the 'Notes' section for more information.
    timestamp_col : str, default="date"
        The column name representing the timestamp in the dataset.
    time_series_data_col : str, default="total_amount_sold"
        The column name representing the time series data.
    model_name : str, default="bqmlforecast.arima_plus_xreg_model"
        The base name for the models.
    train_table_name : str, default="bqmlforecast.training_data"
        The name of the table containing training data.
    test_table_name : str, default="bqmlforecast.test_data"
        The name of the table containing test data.
    holiday_region : str, default="US"
        The holiday region to be used by the models.
    auto_arima : bool, default=True
        Whether to enable AUTO_ARIMA.
    adjust_step_changes : bool, default=True
        Whether to adjust for step changes in the data.
    clean_spikes_and_dips : bool, default=True
        Whether to clean spikes and dips in the data.

    Notes
    -----
    Not specifying a value for `max_items` requires you to use a Google Cloud
    account with billing enabled. If you're not using a Google Cloud account
    with billing enabled, then you should limit the number of items
    to a value smaller than or equal to 4.

    .. important::

        If using a Google Cloud account with billing enabled, running this
        code might incur charges.
    """
    _items_list = (
        items_list if not isinstance(max_items, int) else items_list[:max_items]
    )
    for item_name in track(_items_list, description="Creating models..."):
        query = create_model_query(
            item_name,
            timestamp_col,
            time_series_data_col,
            model_name,
            train_table_name,
            test_table_name,
            holiday_region,
            auto_arima,
            adjust_step_changes,
            clean_spikes_and_dips,
        )
        execute_query_with_retries(client, query)


def train_arima_models(  # pylint: disable=too-many-locals, too-many-arguments
    client: bigquery.Client,
    columns: List[str],
    model: str = "bqmlforecast.arima_model",
    train_table_name: str = "bqmlforecast.training_data",
    test_table_name: str = "bqmlforecast.test_data",
    model_metrics_table_name: str | None = "bqmlforecast.arima_model_metrics",
    time_series_timestamp_col: str = "date",
    time_series_id_col: str = "item_name",
    confidence_level=0.9,
    horizon=7,
):
    """
    Train ARIMA models for a list of columns and store their metrics.

    This function generates and executes 'CREATE MODEL' queries for ARIMA
    models using the specified columns, and evaluates their performance
    by creating tables of model metrics.

    These ARIMA models will then be used to generate the future feature values
    used for forecasting the liquor sales.

    Parameters
    ----------
    client : bigquery.Client
        Instance of the BigQuery client used to execute queries.
    columns : List[str]
        List of columns to be used for creating ARIMA models.
    model : str, default="bqmlforecast.arima_model"
        The base name for the ARIMA models.
    train_table_name : str, default="bqmlforecast.training_data"
        The name of the table containing training data.
    test_table_name : str, default="bqmlforecast.test_data"
        The name of the table containing test data.
    model_metrics_table_name : str or None, default="bqmlforecast.arima_model_metrics"
        The base name for the tables where model metrics will be stored.
    time_series_timestamp_col : str, default="date"
        The column name representing the timestamp in the dataset.
    time_series_id_col : str, default="item_name"
        The column name representing the identifier for the time series.
    confidence_level : float, default=0.9
        The confidence level used in the model evaluation.
    horizon : int, default=7
        The number of time steps (days) to forecast.

    """
    for column in track(columns, description="Creating ARIMA models..."):
        model_name = f"{model}_{column}"
        train_arima_query = f"""
        CREATE OR REPLACE MODEL `{model_name}`
        OPTIONS(
            MODEL_TYPE = 'ARIMA_PLUS',
            AUTO_ARIMA = TRUE,
            HORIZON = {horizon},
            TIME_SERIES_TIMESTAMP_COL = '{time_series_timestamp_col}',
            TIME_SERIES_DATA_COL = '{column}',
            TIME_SERIES_ID_COL = '{time_series_id_col}',
            FORECAST_LIMIT_LOWER_BOUND = 0,
            DECOMPOSE_TIME_SERIES = TRUE,
            HOLIDAY_REGION = 'US',
            DATA_FREQUENCY = 'AUTO_FREQUENCY',
            ADJUST_STEP_CHANGES = TRUE,
            CLEAN_SPIKES_AND_DIPS = TRUE
        ) AS
        SELECT
            {time_series_timestamp_col},
            {column},
            {time_series_id_col}
        FROM
            `{train_table_name}`
        UNION ALL
            (
                SELECT
                    *
                FROM (
                    SELECT
                        t2.{time_series_timestamp_col},
                        t2.{column},
                        t2.{time_series_id_col}
                    FROM
                        `{test_table_name}` AS  t2
                    JOIN
                        (
                            SELECT
                                {time_series_id_col},
                                MAX({time_series_timestamp_col}) AS max_date
                            FROM
                                `{train_table_name}`
                            GROUP BY
                                {time_series_id_col}    
                        ) AS md
                    ON
                        t2.{time_series_id_col} = md.{time_series_id_col}
                    WHERE
                        t2.{time_series_timestamp_col} > md.max_date
                )
            )
        """
        train_arima_job = client.query(train_arima_query)
        train_arima_job.result()

        if isinstance(model_metrics_table_name, str):
            model_metrics_query = f"""
            CREATE OR REPLACE TABLE `{model_metrics_table_name}_{column}` AS (
            SELECT
                *
            FROM
                ML.EVALUATE(
                    MODEL `{model_name}`,
                    (
                        SELECT
                            {time_series_timestamp_col},
                            {time_series_id_col},
                            {column}
                        FROM
                            `{test_table_name}`
                    ),
                    STRUCT({horizon} AS HORIZON, {confidence_level} AS CONFIDENCE_LEVEL)
                )
            )
            """
            model_metrics_job = client.query(model_metrics_query)
            model_metrics_job.result()
